# Internship Progress Log ‚Äì QuantLake üìù

### üìÖ Day 1 ‚Äì 16 June 2025

**Environment Used:**  
Google Colab (also tested in VS Code Jupyter extension)

**Tools Installed:**  
- Python 3.x  
- pandas, numpy, matplotlib, seaborn  
- Git & GitHub configured

**Tasks Completed:**
- Created and structured internship repo
- Practiced Python basics: variables, data types, operators, control flow
- Pushed first notebook to GitHub

**Learnings:**
- Refreshed Python core logic
- Understood daily Git push workflow

**Challenges:**
- No major blockers. Setup was smooth.

---

### üìÖ Day 2 ‚Äì 19 June 2025

**Environment Used:**  
Google Colab (also tested in VS Code Jupyter extension)

**Topics Practiced:**
- Core data structures: list, tuple, set, dictionary
- List comprehension & nested dictionary access
- Writing functions: factorial, prime check
- Using built-in modules: `math`, `random`, `datetime`
- Exception handling: try, except, finally
- Mini logic problems: FizzBuzz, max in list, string reversal

**Tasks Completed:**
- Created and pushed `day2_python_fundamentals.ipynb` inside `training/`
- Implemented multiple practical examples and exercises
- Logged work in this `progress.md` file

**Learnings:**
- Improved confidence with data structures
- Gained better clarity on writing reusable functions
- Learned how to handle runtime errors gracefully
- Strengthened logic through small coding challenges

**Challenges:**
- Slight confusion in exception handling syntax, resolved with testing and debug

---

### üìÖ Day 3 ‚Äì 20 June 2025

**Environment Used:**  
Google Colab (verified in VS Code Jupyter extension)

**Dataset Used:**  
- Seaborn's built-in **Iris** dataset  
- Also created dummy DataFrame and Series using dictionaries and lists

**Topics Practiced:**
- Pandas Series & DataFrame creation
- Dataset exploration using `.head()`, `.info()`, `.describe()`, `.isnull().sum()`
- Accessing and filtering data with `df['col']`, `.loc[]`, `.iloc[]`
- Modifying data (adding, dropping columns)
- Aggregation methods: `.sort_values()`, `.value_counts()`, `.mean()`, `.sum()`, `.max()`, etc.

**Tasks Completed:**
- Created and pushed `day3_pandas_intro.ipynb` inside `training/`
- Practiced Pandas with both dummy and real datasets
- Logged progress with key syntax and learning in this `progress.md`

**Learnings:**
- Understood the difference between Pandas Series and DataFrame
- Learned how to inspect, clean, and manipulate tabular data
- Explored aggregation and statistical summaries for EDA
- Practiced building clean and well-structured Pandas code

**Challenges:**
- Minor confusion with `.iloc[]` slicing and column selection syntax ‚Äî resolved by experimenting with samples

---

### üìÖ Day 4 ‚Äì 23 June 2025

**Environment Used:**  
Google Colab (also tested in VS Code Jupyter extension)

**Dataset Used:**  
- Sample Superstore Dataset (from Kaggle)

**Topics Practiced:**
- Indexing and slicing with `.loc[]` and `.iloc[]`
- Conditional filtering and multi-level sorting
- Identifying and handling missing values using `.isnull()`, `.dropna()`, `.fillna()`
- Grouping and aggregation using `.groupby()` and `.agg()`
- Merging DataFrames using `pd.merge()` with inner and outer joins

**Tasks Completed:**
- Created and pushed `day4_data_manipulation_1.ipynb` inside `training/`
- Applied all core Pandas data manipulation operations
- Logged learnings and insights in this `progress.md` file

**Learnings:**
- Gained clarity on slicing rows and columns with label- and index-based methods
- Learned to clean messy datasets and fill missing data efficiently
- Practiced summarizing data with groupby and multi-aggregation
- Understood real-world joining of datasets via merging techniques

**Challenges:**
- Initially mixed up merge `on=` keys ‚Äî resolved by reading official Pandas docs
- Practiced multiple join types to clearly understand the data impact

--- 

### üìÖ Day 5 ‚Äì 25 June 2025

**Environment Used:**  
Google Colab (verified in VS Code Jupyter extension)

**Dataset Used:**  
- Superstore Sales Dataset (from Kaggle)

**Topics Practiced:**
- Reshaping with `.pivot()`, `.pivot_table()`, `.melt()`
- Applying functions with `.apply()` and `lambda`
- Cleaning/transformation with `.map()` and `.replace()`
- Concatenating DataFrames with `pd.concat()`
- Building end-to-end data transformation pipelines

**Tasks Completed:**
- Created and pushed `day5_data_manipulation_2.ipynb` inside `training/`
- Performed advanced data reshaping, feature engineering, and combination
- Logged today‚Äôs learning and reflections in this `progress.md` file

**Learnings:**
- Understood how to convert wide to long format and vice versa
- Learned how to build derived columns with conditional logic
- Became confident in merging datasets and chaining transformations

**Challenges:**
- Faced minor issues with pivoting on multiple levels ‚Äî resolved with sample testing
- Initially confused with axis parameter in `pd.concat()`, clarified through examples

